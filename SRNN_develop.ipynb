{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Spiking Recurrent Neural Network (SRNN) for Memtransistor Crossbar Array Simulation**\n",
    "### **Neuron**\n",
    "A neuron should be able to change its membrane voltage under different rules, and be fired when current membrane voltage exceed the threshold voltage. Once been fired, the membrane voltage should return to 0.\n",
    "\n",
    "    - (DONE) Integrate-and-fire (IF) neuron\n",
    "    - (TODO) Leaky integrate-and-fire (LIF) neuron\n",
    "    - (TODO) Adaptive leaky integrate-and-fire (ALIF) neuron\n",
    "### **Weight Update methods**\n",
    "    - (TODO) Back propogation (BP) \n",
    "    - (TODO) Back propagation through time (BPTT) \n",
    "    - (TODO) Spike timing depedent plasticity (STDP)\n",
    "### **Model**\n",
    "    - (TODO) train\n",
    "    - (TODO) predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - **Neuron.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from toolbox.tensorflow_einsums.einsum_re_written import einsum_bi_ijk_to_bjk\n",
    "from toolbox.tensorflow_utils import tf_roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cell = tf.keras.layers.AbstractRNNCell\n",
    "IFStateTuple = namedtuple('IFStateTuple', ('v', 'z', 'i_future_buffer', 'z_buffer'))\n",
    "LIFStateTuple = namedtuple('LIFStateTuple', ('v', 'z', 'i_future_buffer', 'z_buffer'))\n",
    "ALIFStateTuple = namedtuple('ALIFStateTuple', ('v', 'z', 'b', 'i_future_buffer', 'z_buffer'))\n",
    "\n",
    "@tf.custom_gradient # Decorator to define a function with a custom gradient.\n",
    "\n",
    "# STDP should be inserted in this function!!!!!\n",
    "def SpikeFunction(v_scaled, dampening_factor):\n",
    "    z_ = tf.math.greater(v_scaled, 0.) # returns the truth/flase value of (x > y) element-wise.\n",
    "    z_ = tf.cast(z_, dtype=tf.float32) # cast z to data type of float32, i.e., true - 1.0, false - 0.0\n",
    "\n",
    "    def grad(dy): \n",
    "        # calculate the gradient for BPTT\n",
    "        dE_dz = dy # E - error\n",
    "        dz_dv_scaled = tf.math.maximum(1 - tf.abs(v_scaled), 0)\n",
    "        dz_dv_scaled *= dampening_factor # dampening_factor = 0.3 for sequantial MNIST in NIPS 2018 \n",
    "\n",
    "        dE_dv_scaled = dE_dz * dz_dv_scaled\n",
    "\n",
    "        return [dE_dv_scaled,\n",
    "                tf.zeros_like(dampening_factor)] \n",
    "        # tf.zeros_like(dampening_factor) - a tensor with shape of 'dampening_factor'.\n",
    "    \n",
    "    # STDP should be inserted here!!!!!\n",
    "\n",
    "    # tf.identity : Return a Tensor with the same shape and contents as input.\n",
    "    return tf.identity(z_, name=\"SpikeFunction\"), grad\n",
    "\n",
    "class IF(Cell):\n",
    "    def __init__(self, n_in, n_rec, thr = 0.03, dt = 1.0, n_refractory=0, \n",
    "        n_delay = 1, capacitance = 1.0, in_neuron_sign=None, rec_neuron_sign=None, dtype=tf.float32):\n",
    "        '''\n",
    "            :param n_refractory: number of refractory time steps - refractory time that the neuron cannot be fired again\n",
    "            :param dtype: data type of the cell tensors\n",
    "            :param n_delay: number of synaptic delay timestep, the delay range goes from 1 to n_delay time steps\n",
    "        '''\n",
    "            \n",
    "        self.n_in = n_in\n",
    "        self.n_rec = n_rec\n",
    "        self.thr = tf.Variable(thr, dtype=dtype, name=\"Threshold\", trainable=False) \n",
    "        self.dt = tf.cast(dt, dtype=dtype)\n",
    "        self.n_refractory = n_refractory #　number of refractory time steps　—　refractory time that the neuron cannot be fired again\n",
    "        self.n_delay = n_delay # number of synaptic delay timestep, the delay range goes from 1 to n_delay time steps\n",
    "        self.capacitance = capacitance\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self._num_units = self.n_rec\n",
    "        self.in_neuron_sign = in_neuron_sign # input current from former layer\n",
    "        self.rec_neuron_sign = rec_neuron_sign # recurrent current from recurrent neurons of current layer\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return IFStateTuple(v=self.n_rec,\n",
    "                            z=self.n_rec,\n",
    "                            i_future_buffer=(self.n_rec, self.n_delay),\n",
    "                            z_buffer=(self.n_rec, self.n_refractory))\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self.n_rec\n",
    "\n",
    "    def zero_state(self, batch_size, dtype = tf.float32, n_rec=None):\n",
    "        if n_rec is None: n_rec = self.n_rec\n",
    "\n",
    "        v0 = tf.zeros(shape=(batch_size, n_rec), dtype=dtype)\n",
    "        z0 = tf.zeros(shape=(batch_size, n_rec), dtype=dtype)\n",
    "\n",
    "        i_buff0 = tf.zeros(shape=(batch_size, n_rec, self.n_delay), dtype=dtype)\n",
    "        z_buff0 = tf.zeros(shape=(batch_size, n_rec, self.n_refractory), dtype=dtype)\n",
    "\n",
    "        return IFStateTuple(\n",
    "            v=v0,\n",
    "            z=z0,\n",
    "            i_future_buffer=i_buff0,\n",
    "            z_buffer=z_buff0\n",
    "        )\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None, dtype=tf.float32):\n",
    "        '''Convert the IF neuron to callable object'''\n",
    "        i_future_buffer = state.i_future_buffer + einsum_bi_ijk_to_bjk(inputs, self.W_in) + einsum_bi_ijk_to_bjk(\n",
    "            state.z, self.W_rec)\n",
    "\n",
    "        new_v, new_z = self.LIF_dynamic(\n",
    "            v=state.v,\n",
    "            z=state.z,\n",
    "            z_buffer=state.z_buffer,\n",
    "            i_future_buffer=i_future_buffer)\n",
    "\n",
    "        new_z_buffer = tf_roll(state.z_buffer, new_z, axis=2)\n",
    "        new_i_future_buffer = tf_roll(i_future_buffer, axis=2)\n",
    "\n",
    "        new_state = LIFStateTuple(v=new_v,\n",
    "                                  z=new_z,\n",
    "                                  i_future_buffer=new_i_future_buffer,\n",
    "                                  z_buffer=new_z_buffer)\n",
    "        return new_z, new_state\n",
    "\n",
    "\n",
    "    def neuronal_dynamic(self, v, z, z_buffer, i_future_buffer):\n",
    "        \"\"\"\n",
    "        Function that generate the next spike and voltage tensor for given cell state.\n",
    "        :param thr - membrane threshold voltage\n",
    "        :param v - current membrane voltage\n",
    "        :param z - input spike train from previous layer at time t\n",
    "        :return: current v, z\n",
    "        \"\"\"\n",
    "\n",
    "        if self.injected_noise_current > 0:\n",
    "            add_current = tf.random_normal(shape=z.shape, stddev=self.injected_noise_current) # add random noise to current\n",
    "\n",
    "        if thr is None: thr = self.thr\n",
    "        if n_refractory is None: n_refractory = self.n_refractory\n",
    "\n",
    "        i_t = i_future_buffer[:, :, 0] + add_current\n",
    "\n",
    "        I_reset = z * thr * self.dt # thr is fixed for LIF neuron, but changable for ALIF neuron. \n",
    "\n",
    "        new_v = v + i_t - I_reset # the membrane voltage at t+dt\n",
    "\n",
    "        # Spike generation\n",
    "        v_scaled = (v - thr) / thr\n",
    "\n",
    "        # new_z = differentiable_spikes(v_scaled=v_scaled)\n",
    "        new_z = SpikeFunction(v_scaled, self.dampening_factor) # update the z value\n",
    "        # return tf.identity(z_, name=\"SpikeFunction\"), grad\n",
    "\n",
    "        if n_refractory > 0:\n",
    "            is_ref = tf.greater(tf.reduce_max(z_buffer[:, :, -n_refractory:], axis=2), 0)\n",
    "            new_z = tf.where(is_ref, tf.zeros_like(new_z), new_z)\n",
    "\n",
    "        new_z = new_z * 1 / self.dt\n",
    "\n",
    "        return new_v, new_z # return the new membrane voltage, and new input spike train"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b98aa36e9225f5dd4bd905022e3163d0382783dad6e20c2e03e2a95af931253"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
